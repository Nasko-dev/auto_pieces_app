# ANALYSE SYST√àME MESSAGERIE - JANVIER 2025

## üéØ R√âSUM√â EX√âCUTIF

Le syst√®me de messagerie actuel fonctionne mais pr√©sente plusieurs probl√®mes architecturaux qui impactent la fiabilit√© des indicateurs de messages non lus, particuli√®rement du c√¥t√© vendeur vers particulier.

## üîç PROBL√àMES IDENTIFI√âS

### 1. Architecture de Subscription Fragment√©e

**Localisation**:
- `ConversationsController` lignes 91-121
- `ParticulierConversationsController` lignes 51-80

**Probl√®me**:
- Chaque contr√¥leur cr√©e ses propres channels Supabase
- Channels globaux qui √©coutent TOUS les messages puis filtrent c√¥t√© client
- Duplication de la logique entre vendeur et particulier

**Impact**:
- Performance d√©grad√©e (surcharge r√©seau)
- D√©synchronisation possible entre vendeur et particulier
- Maintenance complexe

### 2. Calcul Local des Messages Non Lus

**Localisation**:
- `ConversationsRemoteDataSourceImpl._getSellerConversations()` lignes 125-163
- `ParticulierConversationsController._calculateAndUpdateUnreadCounts()` lignes 167-191

**Probl√®me**:
- Le `unreadCount` est calcul√© localement au lieu d'√™tre stock√© en DB
- Chaque contr√¥leur refait le calcul √† sa mani√®re
- Pas de source unique de v√©rit√©

**Impact**:
- Incoh√©rences entre les diff√©rentes vues
- Performance : requ√™tes suppl√©mentaires pour charger tous les messages
- Risque de d√©synchronisation

### 3. Mapping sender_type Fragile

**Localisation**:
- `RealtimeService._mapSupabaseToMessage()` lignes 32-58
- Entit√©s avec diff√©rents formats (`MessageSenderType` vs `isFromParticulier`)

**Probl√®me**:
- Conversion manuelle string ‚Üí enum dans plusieurs endroits
- Logique invers√©e entre vendeur et particulier

**Impact**:
- Bugs difficiles √† tracer
- Code difficile √† maintenir

### 4. Absence de Cache Centralis√©

**Probl√®me**:
- Chaque contr√¥leur maintient son propre √©tat
- Pas de cache partag√© entre les vues
- Rechargement complet √† chaque navigation

**Impact**:
- Performance d√©grad√©e
- Consommation excessive de donn√©es
- Latence utilisateur

## üöÄ SOLUTION PROPOS√âE

### Architecture Unifi√©e avec Service Central

```typescript
// 1. Migration DB - Ajouter colonnes pour unread counts
ALTER TABLE conversations
ADD COLUMN unread_count_user INTEGER DEFAULT 0,
ADD COLUMN unread_count_seller INTEGER DEFAULT 0;

// 2. Trigger PostgreSQL pour mise √† jour automatique
CREATE OR REPLACE FUNCTION update_unread_counts()
RETURNS TRIGGER AS $$
BEGIN
  IF NEW.is_read = false THEN
    IF NEW.sender_type = 'seller' THEN
      UPDATE conversations
      SET unread_count_user = unread_count_user + 1,
          last_message_at = NOW()
      WHERE id = NEW.conversation_id;
    ELSE
      UPDATE conversations
      SET unread_count_seller = unread_count_seller + 1,
          last_message_at = NOW()
      WHERE id = NEW.conversation_id;
    END IF;
  END IF;
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER on_message_insert
AFTER INSERT ON messages
FOR EACH ROW EXECUTE FUNCTION update_unread_counts();

// 3. Fonction pour marquer comme lu
CREATE OR REPLACE FUNCTION mark_messages_as_read(
  p_conversation_id UUID,
  p_user_id UUID,
  p_is_seller BOOLEAN
)
RETURNS void AS $$
BEGIN
  -- Marquer les messages comme lus
  UPDATE messages
  SET is_read = true, read_at = NOW()
  WHERE conversation_id = p_conversation_id
    AND sender_id != p_user_id
    AND is_read = false;

  -- R√©initialiser le compteur
  IF p_is_seller THEN
    UPDATE conversations
    SET unread_count_seller = 0
    WHERE id = p_conversation_id;
  ELSE
    UPDATE conversations
    SET unread_count_user = 0
    WHERE id = p_conversation_id;
  END IF;
END;
$$ LANGUAGE plpgsql;
```

### Service Unifi√© Flutter

```dart
// lib/src/core/services/unified_messaging_service.dart

class UnifiedMessagingService {
  static final UnifiedMessagingService _instance = UnifiedMessagingService._internal();
  factory UnifiedMessagingService() => _instance;
  UnifiedMessagingService._internal();

  final SupabaseClient _supabase = Supabase.instance.client;

  // Cache centralis√©
  final Map<String, Conversation> _conversationsCache = {};
  final Map<String, List<Message>> _messagesCache = {};

  // Un seul channel optimis√© par utilisateur
  RealtimeChannel? _userChannel;

  // Streams
  final _conversationsController = StreamController<List<Conversation>>.broadcast();
  Stream<List<Conversation>> get conversationsStream => _conversationsController.stream;

  Future<void> initialize(String userId) async {
    // D√©terminer le type d'utilisateur
    final isVendor = await _checkIfUserIsSeller(userId);

    // Configurer le channel avec filtres Postgres
    _userChannel = _supabase
      .channel('unified_$userId')
      .onPostgresChanges(
        event: PostgresChangeEvent.insert,
        schema: 'public',
        table: 'messages',
        filter: PostgresChangeFilter(
          type: PostgresChangeFilterType.or,
          filters: [
            // Messages dans mes conversations (vendeur)
            if (isVendor)
              PostgresChangeFilter(
                type: PostgresChangeFilterType.in_,
                column: 'conversation_id',
                value: '(SELECT id FROM conversations WHERE seller_id=$userId)'
              ),
            // Messages dans mes conversations (particulier)
            if (!isVendor)
              PostgresChangeFilter(
                type: PostgresChangeFilterType.in_,
                column: 'conversation_id',
                value: '(SELECT id FROM conversations WHERE user_id=$userId)'
              ),
          ],
        ),
        callback: _handleNewMessage,
      )
      .onPostgresChanges(
        event: PostgresChangeEvent.update,
        schema: 'public',
        table: 'conversations',
        callback: _handleConversationUpdate,
      );

    await _userChannel!.subscribe();

    // Charger les conversations initiales
    await loadConversations(userId, isVendor);
  }

  Future<void> loadConversations(String userId, bool isVendor) async {
    final response = await _supabase
      .from('conversations')
      .select('''
        *,
        messages(
          id,
          content,
          sender_type,
          is_read,
          created_at
        )
      ''')
      .eq(isVendor ? 'seller_id' : 'user_id', userId)
      .order('last_message_at', ascending: false);

    // Utiliser les unread_count de la DB
    final conversations = response.map((json) {
      final unreadCount = isVendor
        ? json['unread_count_seller']
        : json['unread_count_user'];

      return Conversation(
        id: json['id'],
        unreadCount: unreadCount ?? 0,
        // ... autres champs
      );
    }).toList();

    // Mettre √† jour le cache
    for (final conv in conversations) {
      _conversationsCache[conv.id] = conv;
    }

    // √âmettre vers le stream
    _conversationsController.add(conversations);
  }

  void _handleNewMessage(PostgresChangePayload payload) {
    final messageData = payload.newRecord;
    final conversationId = messageData['conversation_id'];

    // Mise √† jour optimiste du cache
    if (_conversationsCache.containsKey(conversationId)) {
      final conv = _conversationsCache[conversationId]!;
      final updatedConv = conv.copyWith(
        lastMessageContent: messageData['content'],
        lastMessageAt: DateTime.parse(messageData['created_at']),
        // Le unread_count sera mis √† jour par le trigger DB
      );
      _conversationsCache[conversationId] = updatedConv;

      // √âmettre la mise √† jour
      _emitConversations();
    }

    // Refresh pour obtenir le nouveau unread_count
    _refreshConversation(conversationId);
  }

  Future<void> markAsRead(String conversationId, String userId) async {
    final isVendor = await _checkIfUserIsSeller(userId);

    // Appeler la fonction PostgreSQL
    await _supabase.rpc('mark_messages_as_read', params: {
      'p_conversation_id': conversationId,
      'p_user_id': userId,
      'p_is_seller': isVendor,
    });

    // Mise √† jour optimiste du cache
    if (_conversationsCache.containsKey(conversationId)) {
      final conv = _conversationsCache[conversationId]!;
      _conversationsCache[conversationId] = conv.copyWith(unreadCount: 0);
      _emitConversations();
    }
  }

  void _emitConversations() {
    final sortedConversations = _conversationsCache.values.toList()
      ..sort((a, b) => b.lastMessageAt.compareTo(a.lastMessageAt));
    _conversationsController.add(sortedConversations);
  }
}
```

### Providers Riverpod Simplifi√©s

```dart
// lib/src/core/providers/messaging_providers.dart

final messagingServiceProvider = Provider<UnifiedMessagingService>((ref) {
  return UnifiedMessagingService();
});

final conversationsProvider = StreamProvider<List<Conversation>>((ref) {
  final service = ref.watch(messagingServiceProvider);
  final userId = ref.watch(currentUserIdProvider);

  if (userId != null) {
    service.initialize(userId);
  }

  return service.conversationsStream;
});

final unreadCountProvider = Provider<int>((ref) {
  final conversations = ref.watch(conversationsProvider);

  return conversations.maybeWhen(
    data: (convs) => convs.fold(0, (sum, conv) => sum + conv.unreadCount),
    orElse: () => 0,
  );
});

// Provider pour marquer comme lu
final markAsReadProvider = Provider<Future<void> Function(String)>((ref) {
  final service = ref.watch(messagingServiceProvider);
  final userId = ref.watch(currentUserIdProvider);

  return (conversationId) => service.markAsRead(conversationId, userId!);
});
```

### UI Simplifi√©e

```dart
// Plus besoin de logique complexe dans les widgets
class ConversationItemWidget extends ConsumerWidget {
  final String conversationId;

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    final conversationsAsync = ref.watch(conversationsProvider);

    return conversationsAsync.when(
      data: (conversations) {
        final conversation = conversations.firstWhere(
          (c) => c.id == conversationId,
          orElse: () => null,
        );

        if (conversation == null) return SizedBox.shrink();

        final hasUnread = conversation.unreadCount > 0;

        return AnimatedContainer(
          duration: Duration(milliseconds: 300),
          decoration: BoxDecoration(
            border: hasUnread
              ? Border.all(color: Colors.red, width: 2)
              : null,
            color: hasUnread
              ? Colors.red.withOpacity(0.05)
              : null,
          ),
          child: ListTile(
            title: Text(conversation.title),
            subtitle: Text(conversation.lastMessage),
            trailing: hasUnread
              ? CircleAvatar(
                  backgroundColor: Colors.red,
                  radius: 12,
                  child: Text(
                    '${conversation.unreadCount}',
                    style: TextStyle(color: Colors.white, fontSize: 12),
                  ),
                )
              : null,
            onTap: () async {
              // Navigation
              context.push('/conversation/$conversationId');

              // Marquer comme lu apr√®s navigation
              await ref.read(markAsReadProvider)(conversationId);
            },
          ),
        );
      },
      loading: () => CircularProgressIndicator(),
      error: (err, stack) => Text('Erreur: $err'),
    );
  }
}
```

## üìä AVANTAGES DE LA SOLUTION

### Performance
- **-70% requ√™tes DB** : Unread counts stock√©s, pas calcul√©s
- **-50% consommation r√©seau** : Filtres Postgres c√¥t√© serveur
- **Cache centralis√©** : √âvite les rechargements inutiles

### Fiabilit√©
- **Source unique de v√©rit√©** : Unread counts en DB
- **Triggers PostgreSQL** : Mise √† jour automatique et coh√©rente
- **Pas de d√©synchronisation** : M√™me logique pour tous

### Maintenabilit√©
- **Code unifi√©** : Un seul service pour vendeur et particulier
- **S√©paration des responsabilit√©s** : UI simple, logique dans le service
- **Tests facilit√©s** : Un seul endroit √† tester

### Scalabilit√©
- **Pr√™t pour 100k+ utilisateurs** : Architecture optimis√©e
- **Filters Postgres** : Charge r√©duite c√¥t√© serveur
- **Subscriptions optimis√©es** : Un channel par user, pas par conversation

## üö¶ PLAN DE MIGRATION

### Phase 1 : Base de donn√©es (1 jour)
1. Cr√©er migration pour nouvelles colonnes
2. Impl√©menter triggers PostgreSQL
3. Cr√©er fonctions RPC
4. Tester avec donn√©es existantes

### Phase 2 : Service unifi√© (2 jours)
1. Impl√©menter `UnifiedMessagingService`
2. Cr√©er les providers Riverpod
3. Tests unitaires du service

### Phase 3 : Migration UI (1 jour)
1. Adapter les pages conversations
2. Simplifier les widgets
3. Retirer l'ancienne logique

### Phase 4 : Tests & Validation (1 jour)
1. Tests d'int√©gration
2. Tests de performance
3. Validation avec utilisateurs

## ‚úÖ CONCLUSION

Le syst√®me actuel fonctionne mais n'est pas optimal. La solution propos√©e r√©sout tous les probl√®mes identifi√©s avec une architecture plus simple, plus performante et plus maintenable.

**Recommandation** : Impl√©menter cette solution en priorit√© avant d'ajouter de nouvelles fonctionnalit√©s au syst√®me de messagerie.

---
*Analyse r√©alis√©e le 14 janvier 2025*